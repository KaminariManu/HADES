{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c3a702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Define class names\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbd093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])# Define transforms: resize, convert to tensor, normalize\n",
    "\n",
    "#Data Augmentation for training\n",
    "robust_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Random crop and resize\n",
    "    transforms.RandomHorizontalFlip(),                    # Random horizontal flip\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Color jitter\n",
    "    transforms.RandomRotation(15),                        # Random rotation\n",
    "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),  # Random blur\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a119ebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as F\n",
    "\n",
    "def unnormalize(img_tensor):\n",
    "    device = img_tensor.device\n",
    "    if img_tensor.dim() == 4:\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406], device=device).view(1, 3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225], device=device).view(1, 3, 1, 1)\n",
    "    else:\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406], device=device).view(3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225], device=device).view(3, 1, 1)\n",
    "    return img_tensor * std + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f5fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_normalization(imgs):\n",
    "    \"\"\"\n",
    "    Convert a batch of images from normalization (mean=0.5, std=0.5)\n",
    "    to GoogLeNet normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]).\n",
    "    imgs: torch.Tensor of shape (B, 3, H, W)\n",
    "    Returns: torch.Tensor of same shape, normalized for GoogLeNet\n",
    "    \"\"\"\n",
    "    # Unnormalize from (0.5, 0.5, 0.5) to [0, 1]\n",
    "    imgs = imgs * 0.5 + 0.5\n",
    "    # Normalize to GoogLeNet\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406], device=imgs.device).view(1, 3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225], device=imgs.device).view(1, 3, 1, 1)\n",
    "    imgs = (imgs - mean) / std\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8534282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.models import GoogLeNet_Weights\n",
    "\n",
    "def get_googlenet(pretrained=True):\n",
    "    if pretrained:\n",
    "        model = models.googlenet(weights=GoogLeNet_Weights.IMAGENET1K_V1)\n",
    "    else:\n",
    "        model = models.googlenet(weights=None, init_weights=True)  # Explicit init\n",
    "    model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22271ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dataset for original images\n",
    "class CIFAR10TorchDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = self.labels[idx][0]\n",
    "        img = img.astype('uint8')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "# Flatten y_train for stratification\n",
    "y_train_flat = y_train.flatten()\n",
    "\n",
    "# Split train into train/val (80/20) with stratification\n",
    "x_train_split, x_val, y_train_split, y_val = train_test_split(\n",
    "    x_train, y_train, test_size=0.2, random_state=42, stratify=y_train_flat\n",
    ")\n",
    "\n",
    "# Datasets: both normal and robust for train, only normal for val/test\n",
    "train_dataset_normal = CIFAR10TorchDataset(x_train_split, y_train_split, transform=transform)\n",
    "train_dataset_robust = CIFAR10TorchDataset(x_train_split, y_train_split, transform=robust_transform)\n",
    "from torch.utils.data import ConcatDataset\n",
    "train_dataset = ConcatDataset([train_dataset_normal, train_dataset_robust])\n",
    "\n",
    "val_dataset = CIFAR10TorchDataset(x_val, y_val, transform=transform)\n",
    "test_dataset = CIFAR10TorchDataset(x_test, y_test, transform=transform)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373bfb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import foolbox as fb\n",
    "\n",
    "def adversarial_train_pgd(\n",
    "    model, train_loader, val_loader, device, epochs=5, lr=1e-3, patience=5,\n",
    "    epsilon=0.05, alpha=0.5, steps=10, rel_stepsize=0.1\n",
    "):\n",
    "    import copy\n",
    "\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    patience_counter = 0\n",
    "    best_val_acc = 0.0\n",
    "    best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [AdvTrain]\", leave=False)\n",
    "        for images, labels in loop:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device).squeeze()\n",
    "\n",
    "            # Putting the images in the range [-1, 1]\n",
    "            images_01 = unnormalize(images)\n",
    "            images_pgd = images_01 * 2 - 1\n",
    "\n",
    "            # Generate adversarial examples using PGD\n",
    "            model.eval()\n",
    "            fmodel = fb.PyTorchModel(model, bounds=(-1, 1))\n",
    "            attack_pgd = fb.attacks.LinfPGD(steps=steps, rel_stepsize=rel_stepsize)\n",
    "            advs, _, _ = attack_pgd(fmodel, images_pgd, labels, epsilons=epsilon)\n",
    "            advs = convert_normalization(advs)  # Convert adversarial images back to original range\n",
    "            model.train()\n",
    "\n",
    "            # Compute loss as weighted sum (Goodfellow style)\n",
    "            outputs_clean = model(images)\n",
    "            outputs_adv = model(advs)\n",
    "            loss_clean = criterion(outputs_clean, labels)\n",
    "            loss_adv = criterion(outputs_adv, labels)\n",
    "            loss = alpha * loss_clean + (1 - alpha) * loss_adv\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accuracy on clean data (for info)\n",
    "            _, predicted = outputs_clean.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "        train_loss = running_loss / total\n",
    "        train_acc = correct / total\n",
    "\n",
    "        # Validation (on clean data)\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        loop_val = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\", leave=False)\n",
    "        with torch.no_grad():\n",
    "            for images, labels in loop_val:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device).squeeze()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "                loop_val.set_postfix(loss=loss.item())\n",
    "        val_loss /= val_total\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "              f\"AdvTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # Early stopping check (on accuracy as here we are doing adversarial training)\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                model.load_state_dict(best_weights)\n",
    "                break\n",
    "\n",
    "    print(f\"Best validation accuracy for alpha={alpha}: {best_val_acc:.4f}\")\n",
    "    return best_val_acc, best_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a98fab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multiple_alphas_epsilons_and_save_best_pgd(\n",
    "    model_fn, train_loader, val_loader, device, alphas, epsilons,\n",
    "    epochs=5, lr=1e-3, patience=5, steps=10, rel_stepsize=0.1, save_path=\"best_adv_pgd_aug.pth\"\n",
    "):\n",
    "    best_acc = 0.0\n",
    "    best_weights = None\n",
    "    best_alpha = None\n",
    "    best_epsilon = None\n",
    "    for alpha in alphas:\n",
    "        for epsilon in epsilons:\n",
    "            print(f\"\\nTraining with alpha={alpha}, epsilon={epsilon}\")\n",
    "            model = model_fn()\n",
    "            val_acc, weights = adversarial_train_pgd(\n",
    "                model, train_loader, val_loader, device,\n",
    "                epochs=epochs, lr=lr, patience=patience,\n",
    "                epsilon=epsilon, alpha=alpha, steps=steps, rel_stepsize=rel_stepsize\n",
    "            )\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                best_weights = weights\n",
    "                best_alpha = alpha\n",
    "                best_epsilon = epsilon\n",
    "    if best_weights is not None:\n",
    "        torch.save(best_weights, save_path)\n",
    "        print(f\"Saved best model (alpha={best_alpha}, epsilon={best_epsilon}, val_acc={best_acc:.4f}) to {save_path}\")\n",
    "    return best_acc, best_alpha, best_epsilon, save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d748fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())  # Should be True\n",
    "print(torch.cuda.device_count())  # Should be > 0\n",
    "print(torch.cuda.get_device_name(0))  # Should return GPU name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2378fb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1347b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fgsm = get_googlenet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b9c129",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Using device: {device}\")\n",
    "num_epochs = 100\n",
    "learning_rate = 1e-4\n",
    "\n",
    "alphas = [0.3, 0.5, 0.8]\n",
    "epsilons = [0.05, 0.1]\n",
    "best_acc, best_alpha, best_epsilon, best_path = train_multiple_alphas_epsilons_and_save_best_pgd(\n",
    "    lambda: get_googlenet(pretrained=True),\n",
    "    train_loader, val_loader, device,\n",
    "    alphas=alphas, \n",
    "    epsilon=epsilons,epochs=5, \n",
    "    lr=1e-3, patience=5,\n",
    "    save_path=\"best_adv_pgd_aug.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ab82a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "def run_attacks_metrics(model, test_loader, device, epsilons=[0.01, 0.03, 0.05]):\n",
    "    import foolbox as fb\n",
    "\n",
    "    model.eval()\n",
    "    fmodel = fb.PyTorchModel(model, bounds=(-1, 1))\n",
    "    class_names = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    results = []\n",
    "\n",
    "    # For aggregate confusion\n",
    "    fgsm_agg_conf = np.zeros((10, 10), dtype=int)\n",
    "    pgd_agg_conf = np.zeros((10, 10), dtype=int)\n",
    "\n",
    "    # Collect all test images and labels\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    for images, labels in test_loader:\n",
    "        all_images.append(images)\n",
    "        all_labels.append(labels)\n",
    "    all_images = torch.cat(all_images, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "    total_images = all_images.shape[0]\n",
    "\n",
    "    fgsm_conf_matrices = []\n",
    "    pgd_conf_matrices = []\n",
    "\n",
    "    # PSNR metrics\n",
    "    fgsm_psnr_per_eps = {}\n",
    "    fgsm_psnr_per_class = {}\n",
    "    pgd_psnr_per_eps = {}\n",
    "    pgd_psnr_per_class = {}\n",
    "\n",
    "    for eps in epsilons:\n",
    "        batch_size = 128\n",
    "        clean_correct = 0\n",
    "        fgsm_correct = 0\n",
    "        pgd_correct = 0\n",
    "        total = 0\n",
    "\n",
    "        fgsm_confusion = np.zeros((10, 10), dtype=int)\n",
    "        pgd_confusion = np.zeros((10, 10), dtype=int)\n",
    "\n",
    "        # For PSNR\n",
    "        fgsm_psnr_list = []\n",
    "        fgsm_psnr_per_class_list = [[] for _ in range(10)]\n",
    "        pgd_psnr_list = []\n",
    "        pgd_psnr_per_class_list = [[] for _ in range(10)]\n",
    "\n",
    "        for i in range(0, total_images, batch_size):\n",
    "            batch_imgs = all_images[i:i+batch_size].to(device)\n",
    "            batch_lbls = all_labels[i:i+batch_size].to(device)\n",
    "\n",
    "            attack_fgsm = fb.attacks.FGSM()\n",
    "            advs_fgsm, _, _ = attack_fgsm(fmodel, batch_imgs, batch_lbls, epsilons=eps)\n",
    "            attack_pgd = fb.attacks.LinfPGD(steps=10, rel_stepsize=0.1)\n",
    "            advs_pgd, _, _ = attack_pgd(fmodel, batch_imgs, batch_lbls, epsilons=eps)\n",
    "\n",
    "            batch_imgs_norm = convert_normalization(batch_imgs)  # Convert images for model\n",
    "            advs_fgsm_norm = convert_normalization(advs_fgsm)  # Convert FGSM adversarial images\n",
    "            advs_pgd_norm = convert_normalization(advs_pgd)  # Convert PGD adversarial images\n",
    "\n",
    "            clean_pred = model(batch_imgs_norm).argmax(axis=1)\n",
    "            fgsm_pred = model(advs_fgsm_norm).argmax(axis=1)\n",
    "            pgd_pred = model(advs_pgd_norm).argmax(axis=1)\n",
    "\n",
    "            clean_correct += (clean_pred == batch_lbls).sum().item()\n",
    "            fgsm_correct += (fgsm_pred == batch_lbls).sum().item()\n",
    "            pgd_correct += (pgd_pred == batch_lbls).sum().item()\n",
    "            total += batch_lbls.size(0)\n",
    "\n",
    "            for t, p in zip(batch_lbls.cpu().numpy(), fgsm_pred.cpu().numpy()):\n",
    "                fgsm_confusion[t, p] += 1\n",
    "                fgsm_agg_conf[t, p] += 1\n",
    "            for t, p in zip(batch_lbls.cpu().numpy(), pgd_pred.cpu().numpy()):\n",
    "                pgd_confusion[t, p] += 1\n",
    "                pgd_agg_conf[t, p] += 1\n",
    "\n",
    "            # FGSM PSNR calculation (unnormalize to [0,1] for PSNR)\n",
    "            batch_imgs_unnorm = (batch_imgs_norm * torch.tensor([0.229, 0.224, 0.225], device=device).view(1,3,1,1)) + torch.tensor([0.485, 0.456, 0.406], device=device).view(1,3,1,1)\n",
    "            advs_fgsm_unnorm = (advs_fgsm_norm * torch.tensor([0.229, 0.224, 0.225], device=device).view(1,3,1,1)) + torch.tensor([0.485, 0.456, 0.406], device=device).view(1,3,1,1)\n",
    "            batch_imgs_unnorm = torch.clamp(batch_imgs_unnorm, 0, 1)\n",
    "            advs_fgsm_unnorm = torch.clamp(advs_fgsm_unnorm, 0, 1)\n",
    "            for j in range(batch_imgs_unnorm.shape[0]):\n",
    "                psnr_fgsm = psnr(\n",
    "                    batch_imgs_unnorm[j].cpu().numpy(),\n",
    "                    advs_fgsm_unnorm[j].cpu().numpy(),\n",
    "                    data_range=1.0\n",
    "                )\n",
    "                fgsm_psnr_list.append(psnr_fgsm)\n",
    "                label = int(batch_lbls[j].item())\n",
    "                fgsm_psnr_per_class_list[label].append(psnr_fgsm)\n",
    "\n",
    "            # PGD PSNR calculation (unnormalize to [0,1] for PSNR)\n",
    "            advs_pgd_unnorm = (advs_pgd_norm * torch.tensor([0.229, 0.224, 0.225], device=device).view(1,3,1,1)) + torch.tensor([0.485, 0.456, 0.406], device=device).view(1,3,1,1)\n",
    "            advs_pgd_unnorm = torch.clamp(advs_pgd_unnorm, 0, 1)\n",
    "            for j in range(batch_imgs_unnorm.shape[0]):\n",
    "                psnr_pgd = psnr(\n",
    "                    batch_imgs_unnorm[j].cpu().numpy(),\n",
    "                    advs_pgd_unnorm[j].cpu().numpy(),\n",
    "                    data_range=1.0\n",
    "                )\n",
    "                pgd_psnr_list.append(psnr_pgd)\n",
    "                label = int(batch_lbls[j].item())\n",
    "                pgd_psnr_per_class_list[label].append(psnr_pgd)\n",
    "\n",
    "        clean_acc = 100 * clean_correct / total\n",
    "        fgsm_acc = 100 * fgsm_correct / total\n",
    "        pgd_acc = 100 * pgd_correct / total\n",
    "        results.append({'epsilon': eps, 'clean_acc': clean_acc, 'fgsm_acc': fgsm_acc, 'pgd_acc': pgd_acc})\n",
    "\n",
    "        # Store PSNR metrics\n",
    "        fgsm_psnr_per_eps[eps] = np.mean(fgsm_psnr_list) if fgsm_psnr_list else float('nan')\n",
    "        fgsm_psnr_per_class[eps] = [np.mean(fgsm_psnr_per_class_list[c]) if fgsm_psnr_per_class_list[c] else float('nan') for c in range(10)]\n",
    "        pgd_psnr_per_eps[eps] = np.mean(pgd_psnr_list) if pgd_psnr_list else float('nan')\n",
    "        pgd_psnr_per_class[eps] = [np.mean(pgd_psnr_per_class_list[c]) if pgd_psnr_per_class_list[c] else float('nan') for c in range(10)]\n",
    "\n",
    "        fgsm_conf_matrices.append(fgsm_confusion.copy())\n",
    "        pgd_conf_matrices.append(pgd_confusion.copy())\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    return {\n",
    "        \"fgsm_conf_matrices\": fgsm_conf_matrices,\n",
    "        \"pgd_conf_matrices\": pgd_conf_matrices,\n",
    "        \"fgsm_agg_conf\": fgsm_agg_conf,\n",
    "        \"pgd_agg_conf\": pgd_agg_conf,\n",
    "        \"class_names\": class_names,\n",
    "        \"results\": df_results,\n",
    "        \"fgsm_psnr_per_eps\": fgsm_psnr_per_eps,\n",
    "        \"fgsm_psnr_per_class\": fgsm_psnr_per_class,\n",
    "        \"pgd_psnr_per_eps\": pgd_psnr_per_eps,\n",
    "        \"pgd_psnr_per_class\": pgd_psnr_per_class\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535a8fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_attack_metrics(metrics, attack_type=\"pgd\", save_prefix=None):\n",
    "    \"\"\"\n",
    "    Print and optionally save aggregate confusion, per-class confusion, and accuracy table for FGSM or PGD attacks.\n",
    "    attack_type: \"fgsm\" or \"pgd\"\n",
    "    save_prefix: if provided, saves CSVs with this prefix (e.g., \"student_pgd\")\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    assert attack_type in (\"fgsm\", \"pgd\"), \"attack_type must be 'fgsm' or 'pgd'\"\n",
    "\n",
    "    agg_conf_key = f\"{attack_type}_agg_conf\"\n",
    "    psnr_per_eps_key = f\"{attack_type}_psnr_per_eps\"\n",
    "    psnr_per_class_key = f\"{attack_type}_psnr_per_class\"\n",
    "\n",
    "    print(f\"\\nAggregate {attack_type.upper()} confusion (all epsilons):\")\n",
    "    agg_conf = metrics[agg_conf_key]\n",
    "    agg_df = pd.DataFrame(agg_conf, index=metrics[\"class_names\"], columns=metrics[\"class_names\"])\n",
    "    print(agg_df)\n",
    "    if save_prefix:\n",
    "        agg_df.to_csv(f\"{save_prefix}_agg_conf_{attack_type}.csv\")\n",
    "\n",
    "    # Calculate mean PSNR per epsilon and per class\n",
    "    if psnr_per_eps_key in metrics and psnr_per_class_key in metrics:\n",
    "        mean_psnr_per_eps = metrics[psnr_per_eps_key]  # dict: epsilon -> mean psnr\n",
    "        mean_psnr_per_class = metrics[psnr_per_class_key]  # dict: epsilon -> [mean psnr per class]\n",
    "    else:\n",
    "        print(f\"Warning: {attack_type.upper()} PSNR metrics not found in metrics dict, computing for last epsilon only.\")\n",
    "        mean_psnr_per_eps = {}\n",
    "        mean_psnr_per_class = {}\n",
    "\n",
    "    # Per-class confusion summary with mean PSNR per class\n",
    "    summary = []\n",
    "    for idx, row in enumerate(agg_conf):\n",
    "        true_label = metrics[\"class_names\"][idx]\n",
    "        row_copy = row.copy()\n",
    "        row_copy[idx] = 0\n",
    "        total_confused = row_copy.sum()\n",
    "        if total_confused == 0:\n",
    "            most_confused = \"-\"\n",
    "            count = 0\n",
    "            percentage = 0.0\n",
    "        else:\n",
    "            most_confused_idx = np.argmax(row_copy)\n",
    "            most_confused = metrics[\"class_names\"][most_confused_idx]\n",
    "            count = row_copy[most_confused_idx]\n",
    "            percentage = 100.0 * count / total_confused\n",
    "        # Get mean PSNR for this class (for the last epsilon)\n",
    "        mean_psnr = None\n",
    "        if psnr_per_class_key in metrics and metrics[psnr_per_class_key]:\n",
    "            last_eps = list(metrics[psnr_per_class_key].keys())[-1]\n",
    "            mean_psnr = metrics[psnr_per_class_key][last_eps][idx]\n",
    "        summary.append({\n",
    "            \"True Label\": true_label,\n",
    "            \"Most Confused With\": most_confused,\n",
    "            \"Count\": count,\n",
    "            \"Percentage\": f\"{percentage:.2f}%\",\n",
    "            \"Mean PSNR\": f\"{mean_psnr:.2f}\" if mean_psnr is not None else \"-\"\n",
    "        })\n",
    "    summary_df = pd.DataFrame(summary)\n",
    "    print(summary_df.to_markdown(index=False))\n",
    "    if save_prefix:\n",
    "        summary_df.to_csv(f\"{save_prefix}_perclass_{attack_type}.csv\", index=False)\n",
    "\n",
    "    # Show accuracy table with mean PSNR per epsilon\n",
    "    print(f\"\\nAccuracy Table ({attack_type.upper()}):\")\n",
    "    df_results = metrics[\"results\"]\n",
    "    if psnr_per_eps_key in metrics:\n",
    "        df_results = df_results.copy()\n",
    "        col_name = f\"mean_psnr_{attack_type}\"\n",
    "        df_results[col_name] = df_results[\"epsilon\"].map(lambda eps: f\"{metrics[psnr_per_eps_key][eps]:.2f}\")\n",
    "    print(df_results.to_markdown(index=False))\n",
    "    if save_prefix:\n",
    "        df_results.to_csv(f\"{save_prefix}_accuracy_{attack_type}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cecc6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Foolbox setup\n",
    "transform_fgsm = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "test_dataset_attack = CIFAR10TorchDataset(x_test, y_test, transform=transform_fgsm)\n",
    "test_loader_attack = DataLoader(test_dataset_attack, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041435ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_metrics(model_path, pretrained=True):\n",
    "    \"\"\"\n",
    "    Loads a GoogLeNet model from the given path, evaluates it on adversarial attacks,\n",
    "    and prints FGSM and PGD metrics.\n",
    "    \"\"\"\n",
    "    model = get_googlenet(pretrained=pretrained)\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))\n",
    "    model.eval()\n",
    "\n",
    "    epsilons = np.arange(0.05, 0.21, 0.05)\n",
    "    metrics = run_attacks_metrics(model, test_loader_attack, device, epsilons=epsilons)\n",
    "    print_attack_metrics(metrics, attack_type=\"fgsm\")\n",
    "    print_attack_metrics(metrics, attack_type=\"pgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85434291",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_metrics(\"best_adv_pgd_aug.pth\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
